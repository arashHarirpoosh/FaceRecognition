{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RetinaFaceTracker_retinaface_pytorch_lib.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "OMGW_3GxZweU",
        "8d2cUCXDzd_s"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arashHarirpoosh/FaceRecognition/blob/main/RetinaFaceTracker_retinaface_pytorch_lib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2OVpq8Xrg74"
      },
      "source": [
        "# Import lib's"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4o4dKRX9Vbjx",
        "outputId": "0ad0be24-f2e5-42ae-d157-e3510eca9911"
      },
      "source": [
        "!pip install pytube\n",
        "!pip install --upgrade youtube-dl\n",
        "!pip install 'h5py==2.10.0' --force-reinstall\n",
        "# !pip install retinaface\n",
        "!pip install deepface\n",
        "!pip install -U retinaface_pytorch > /dev/null"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-11.0.1-py3-none-any.whl (56 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▉                          | 10 kB 22.7 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 20 kB 24.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 30 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 40 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 56 kB 2.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-11.0.1\n",
            "Collecting youtube-dl\n",
            "  Downloading youtube_dl-2021.6.6-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 5.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: youtube-dl\n",
            "Successfully installed youtube-dl-2021.6.6\n",
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting six\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting numpy>=1.7\n",
            "  Downloading numpy-1.21.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 198 kB/s \n",
            "\u001b[?25hInstalling collected packages: six, numpy, h5py\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.6.0 requires h5py~=3.1.0, but you have h5py 2.10.0 which is incompatible.\n",
            "tensorflow 2.6.0 requires numpy~=1.19.2, but you have numpy 1.21.2 which is incompatible.\n",
            "tensorflow 2.6.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed h5py-2.10.0 numpy-1.21.2 six-1.16.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepface\n",
            "  Downloading deepface-0.0.68-py3-none-any.whl (61 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▍                          | 10 kB 21.3 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 20 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 30 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 40 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting gdown>=3.10.1\n",
            "  Downloading gdown-4.0.2.tar.gz (10 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from deepface) (1.1.4)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (1.21.2)\n",
            "Collecting retina-face>=0.0.1\n",
            "  Downloading retina_face-0.0.5-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (4.62.3)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (2.6.0)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (2.6.0)\n",
            "Requirement already satisfied: opencv-python>=3.4.4 in /usr/local/lib/python3.7/dist-packages (from deepface) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (7.1.2)\n",
            "Collecting mtcnn>=0.1.0\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 10.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.7/dist-packages (from deepface) (1.1.5)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->deepface) (7.1.2)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->deepface) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->deepface) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->deepface) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->deepface) (1.16.0)\n",
            "Requirement already satisfied: requests[socks]>=2.12.0 in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->deepface) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->deepface) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=1.1.2->deepface) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.4->deepface) (2018.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.12.0->gdown>=3.10.1->deepface) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.12.0->gdown>=3.10.1->deepface) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.12.0->gdown>=3.10.1->deepface) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.12.0->gdown>=3.10.1->deepface) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.12.0->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Collecting h5py~=3.1.0\n",
            "  Downloading h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 45.4 MB/s \n",
            "\u001b[?25hCollecting numpy>=1.14.0\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 184 kB/s \n",
            "\u001b[?25hCollecting six\n",
            "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (2.6.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.12)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (2.6.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.1.2)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (0.12.0)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (5.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.1.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (0.4.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (3.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.41.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (3.7.4.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (3.3.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (0.37.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=1.9.0->deepface) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (0.4.6)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (3.6.0)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-4.0.2-py3-none-any.whl size=10613 sha256=5d2a186f772f88b4da023aadc82944d74f0789c93147d9180c325624774af793\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/20/08/4d138cf98df8fe9e14e369c7de79e01c5cabca55b0f58cef3a\n",
            "Successfully built gdown\n",
            "Installing collected packages: six, numpy, h5py, gdown, retina-face, mtcnn, deepface\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.2\n",
            "    Uninstalling numpy-1.21.2:\n",
            "      Successfully uninstalled numpy-1.21.2\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 2.10.0\n",
            "    Uninstalling h5py-2.10.0:\n",
            "      Successfully uninstalled h5py-2.10.0\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 3.6.4\n",
            "    Uninstalling gdown-3.6.4:\n",
            "      Successfully uninstalled gdown-3.6.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed deepface-0.0.68 gdown-4.0.2 h5py-3.1.0 mtcnn-0.1.1 numpy-1.19.5 retina-face-0.0.5 six-1.15.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.20 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.4.1 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.28.0 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY_wFD3waS6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e50fd4a4-9ac4-49c4-8d49-a97bc3db87d5"
      },
      "source": [
        "# !rm ./*jpg\n",
        "# %rm -rf drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove './*jpg': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TvTE0WoVlYV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d868447e-0664-4c92-e7e1-edfa8cdd64c9"
      },
      "source": [
        "from pytube import YouTube\n",
        "from pytube.exceptions import RegexMatchError\n",
        "import youtube_dl\n",
        "import dlib\n",
        "# from retinaface import RetinaFace\n",
        "from deepface import DeepFace\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "import cv2\n",
        "import os\n",
        "import threading\n",
        "import time\n",
        "import torch\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import numpy as np\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "from retinaface.pre_trained_models import get_model\n",
        "from retinaface.utils import vis_annotations\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory  /root /.deepface created\n",
            "Directory  /root /.deepface/weights created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwMP93nlXdTY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4edbfe6a-0263-44a5-e6b4-ae1c451718ca"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMGW_3GxZweU"
      },
      "source": [
        "#Codes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODNBIwBaWOfL"
      },
      "source": [
        "def check_tracker_quality(face_trackers, base_image, frame_num, quality_thresh_hold=7):\n",
        "    # Update all the trackers and remove the ones for which the update\n",
        "    # indicated the quality was not good enough\n",
        "    fids_to_delete = []\n",
        "    for fid in face_trackers.keys():\n",
        "        trackingQuality = face_trackers[fid].update(base_image)\n",
        "\n",
        "        # If the tracking quality is good enough, we must delete\n",
        "        # this tracker\n",
        "        if trackingQuality < quality_thresh_hold:\n",
        "            fids_to_delete.append(fid)\n",
        "\n",
        "    for fid in fids_to_delete:\n",
        "        print(\"Removing tracker \" + str(fid) + \" from list of trackers\")\n",
        "        del face_trackers[fid]\n",
        "        df.loc[df['faceID'] == float(fid), 'LastFrame'] = frame_num\n",
        "    return face_trackers\n",
        "\n",
        "\n",
        "def create_new_tracker(current_face_id, frame, loc):\n",
        "    print(\"Creating new tracker \" + str(current_face_id))\n",
        "\n",
        "    x, y, w, h = loc\n",
        "    # Create and store the tracker\n",
        "    tracker = dlib.correlation_tracker()\n",
        "    tracker.start_track(frame,\n",
        "                        dlib.rectangle(x - int(w / 4),\n",
        "                                       y - int(h / 4),\n",
        "                                       x + w + int(w / 4),\n",
        "                                       y + h + int(h / 4)))\n",
        "    return tracker"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeOW3WBSZ5bE"
      },
      "source": [
        "def do_recognize_person(face_names, fid, face_img):\n",
        "    verified_identity = None\n",
        "    try:\n",
        "        face_img_bgr = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
        "        df_fr = DeepFace.find(face_img_bgr,\n",
        "                           db_path=\"/content/FaceDataBase\",\n",
        "                           enforce_detection=False,\n",
        "                           detector_backend='retinaface',\n",
        "                           model_name='ArcFace',\n",
        "                           model=model,\n",
        "                           distance_metric=\"euclidean_l2\")\n",
        "        print(df_fr)\n",
        "        print()\n",
        "        # filtered_faced = df_fr[df_fr['ArcFace_euclidean_l2'] <= 1]\n",
        "        closest_identity = df_fr.loc[df_fr['ArcFace_euclidean_l2'].idxmin()]\n",
        "        print(closest_identity['identity'])\n",
        "        # verified_identity = closest_identity['identity'].split('/')[-2].split('\\\\')[1]\n",
        "        verified_identity = closest_identity['identity'].split('/')[-2]\n",
        "\n",
        "        print()\n",
        "        print(verified_identity)\n",
        "        del df_fr\n",
        "        gc.collect()\n",
        "    except (ValueError, cv2.error):\n",
        "        gc.collect()\n",
        "        print('No Face Detected')\n",
        "        # all_faces = RetinaFace.detect_faces(data)\n",
        "        # print(all_faces)\n",
        "        # cv2.imshow('face', face_img)\n",
        "        # cv2.waitKey()\n",
        "\n",
        "    num_of_zeros = 3 - len(str(fid))\n",
        "    if verified_identity is None:\n",
        "        face_names[fid] = {\n",
        "            'name': '{person_id}'.format(person_id=num_of_zeros * '0' + str(fid)),\n",
        "            'detected': False\n",
        "        }\n",
        "    else:\n",
        "        face_names[fid] = {\n",
        "            'name': verified_identity,\n",
        "            'dir': '{person_id}'.format(person_id=verified_identity + '/' + num_of_zeros * '0' + str(fid)),\n",
        "            'detected': True\n",
        "        }\n",
        "\n",
        "\n",
        "def check_existence_of_new_faces(result_list, face_trackers,\n",
        "                                 face_names, frame, current_face_id, frame_num):\n",
        "    verified_trackers = []\n",
        "    for result in result_list:\n",
        "      if len(result['bbox']) > 3:\n",
        "        x, y, x1, y1 = result['bbox']\n",
        "        w, h = abs(x1 - x), abs(y1 - y)\n",
        "\n",
        "        # Calculate the center point\n",
        "        x_bar = (x + x1) / 2\n",
        "        y_bar = (y + y1) / 2\n",
        "\n",
        "        # Variable holding information which faceid we\n",
        "        # matched with\n",
        "        matched_fid = None\n",
        "\n",
        "        # Now loop over all the trackers and check if the\n",
        "        # center point of the face is within the box of a\n",
        "        # tracker\n",
        "        for fid in face_trackers.keys():\n",
        "            tracked_position = face_trackers[fid].get_position()\n",
        "            t_x = int(tracked_position.left())\n",
        "            t_y = int(tracked_position.top())\n",
        "            t_w = int(tracked_position.width())\n",
        "            t_h = int(tracked_position.height())\n",
        "\n",
        "            # calculate the center point\n",
        "            t_x_bar = t_x + 0.5 * t_w\n",
        "            t_y_bar = t_y + 0.5 * t_h\n",
        "\n",
        "            # check if the center point of the face is within the\n",
        "            # rectangle of a tracker region. Also, the center point\n",
        "            # of the tracker region must be within the region\n",
        "            # detected as a face. If both of these conditions hold\n",
        "            # we have a match\n",
        "            if ((t_x <= x_bar <= (t_x + t_w)) and\n",
        "                    (t_y <= y_bar <= (t_y + t_h)) and\n",
        "                    (x <= t_x_bar <= (x + w)) and\n",
        "                    (y <= t_y_bar <= (y + h))):\n",
        "                matched_fid = fid\n",
        "                verified_trackers.append(fid)\n",
        "\n",
        "        if matched_fid is None:\n",
        "            loc = [x, y, w, h]\n",
        "            tracker = create_new_tracker(current_face_id, frame, loc)\n",
        "            df.loc[df.shape[0] + 1] = [current_face_id, None, frame_num, None, x, y, w, h, None]\n",
        "\n",
        "            face_trackers[current_face_id] = tracker\n",
        "            verified_trackers.append(current_face_id)\n",
        "            # Start a new thread that is used to simulate\n",
        "            # face recognition. This is not yet implemented in this\n",
        "            # version :)\n",
        "            # t = threading.Thread(target=do_recognize_person,\n",
        "            #                      args=(face_names, current_face_id))\n",
        "            # t.start()\n",
        "            # Increase the currentFaceID counter\n",
        "            current_face_id += 1\n",
        "\n",
        "    # Remove the trackers that are not in the second detection\n",
        "    all_fids = face_trackers.copy().keys()\n",
        "    for fid in all_fids:\n",
        "        if fid not in verified_trackers:\n",
        "            print(\"Removing tracker \" + str(fid) +\n",
        "                  \" from list of trackers because of not appearing in the second detection\")\n",
        "            del face_trackers[fid]\n",
        "            df.loc[df['faceID'] == float(fid), 'LastFrame'] = frame_num\n",
        "    del all_fids\n",
        "            \n",
        "    return current_face_id, face_trackers"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3j-hgcLZ-pU"
      },
      "source": [
        "def plot_image_with_boxes(frame, face_trackers, face_name, num_of_digits,\n",
        "                          frame_number, output_file_name, face_shapes=None, save_image=True):\n",
        "    face_img = frame.copy()\n",
        "    for fid in face_trackers.keys():\n",
        "        tracked_position = face_trackers[fid].get_position()\n",
        "        t_x = int(tracked_position.left())\n",
        "        t_y = int(tracked_position.top())\n",
        "        t_w = int(tracked_position.width())\n",
        "        t_h = int(tracked_position.height())\n",
        "\n",
        "        # face = frame[t_y:t_y + t_h, t_x:t_x + t_w]\n",
        "        face = face_img[t_y:t_y + t_h, t_x:t_x + t_w]\n",
        "        if face_shapes is not None:\n",
        "            face = cv2.resize(face, face_shapes, fx=0, fy=0, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "        if fid in face_name.keys():\n",
        "            box_name = face_name[fid]['name']\n",
        "\n",
        "        else:\n",
        "            box_name = 'Detecting...'\n",
        "            start = time.time()\n",
        "            do_recognize_person(face_name, fid, face)\n",
        "            elapsed_verification_time.append(time.time() - start)\n",
        "        if save_image:\n",
        "            if face_name[fid]['detected']:\n",
        "                df.loc[df['faceID'] == float(fid), 'Identity'] = face_name[fid]['name']\n",
        "                directory = '/'.join(output_file_name) + '/labeled/' + face_name[fid]['dir']\n",
        "                id_person = face_name[fid]['dir'].split('/')[1]\n",
        "            else:\n",
        "                directory = '/'.join(output_file_name) + '/unlabeled/' + face_name[fid]['name']\n",
        "                id_person = face_name[fid]['name']\n",
        "            # directory = output_file_name + '\\\\unlabeled\\\\' + face_name[fid]\n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "\n",
        "            num_of_zeros = num_of_digits - len(str(frame_number))\n",
        "            img_name = directory + '/{source}_{n_video}_{frameNumber}_{id_p}_{x}_{y}_{h}_{w}.jpg'.format(\n",
        "                source=output_file_name[-2], n_video=output_file_name[-1]\n",
        "                , frameNumber=num_of_zeros * '0' + str(frame_number)\n",
        "                , id_p=id_person, x=t_x, y=t_y, h=t_h, w=t_w)\n",
        "\n",
        "            try:\n",
        "                cv2.imwrite(img_name, face)\n",
        "            except cv2.error:\n",
        "                pass\n",
        "\n",
        "        cv2.rectangle(frame, (t_x, t_y),\n",
        "                      (t_x + t_w, t_y + t_h),\n",
        "                      (0, 0, 255), 2)\n",
        "        cv2.putText(frame, box_name, (int(t_x + t_w / 2), int(t_y)),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    0.5, (204, 204, 0), 2)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBLkYTH4aCgi"
      },
      "source": [
        "\n",
        "def face_tracking(path, output_file_name, detection_quality_tsh=7, save_image=True, show_result=True,\n",
        "                  face_detection_tsh=10, resize_faces_shape=None, desired_time=None, start_frame=0, current_face_id=1):\n",
        "   \n",
        "    if show_result:\n",
        "        cv2.namedWindow(\"Face-Tracking\", cv2.WINDOW_AUTOSIZE)  ###make window for image or video\n",
        "\n",
        "        # Start the window thread for the two windows we are using\n",
        "        cv2.startWindowThread()\n",
        "\n",
        "    # Used as counter variable\n",
        "    frame_counter = 0\n",
        "    # current_face_id = 1\n",
        "\n",
        "    # Variables holding the correlation trackers and the name per faceid\n",
        "    face_trackers = {}\n",
        "    face_names = {}\n",
        "\n",
        "    # Check to see if previous run is available continue the last run\n",
        "    framePath = '/'.join(output_file_name)\n",
        "    runInfoAddr = framePath + '/runInfo.csv'\n",
        "    if os.path.isfile(runInfoAddr):\n",
        "      # df = pd.read_csv(runInfoAddr)\n",
        "      frame_counter = int(df.iloc[0]['frameCounter'])\n",
        "      start_frame = frame_counter\n",
        "      current_face_id = int(df['faceID'].loc[df['faceID'].idxmax()]) + 1\n",
        "      print(current_face_id)\n",
        "      for index, row in df.iterrows():\n",
        "        if not pd.notnull(row['LastFrame']):\n",
        "          vidObj = cv2.VideoCapture(path)\n",
        "          vidObj.set(1, start_frame - 1)\n",
        "          success, frame = vidObj.read()\n",
        "          del vidObj\n",
        "          fid = int(row['faceID'])\n",
        "          loc = [int(row['loc_x']), int(row['loc_y']), int(row['loc_w']), int(row['loc_h'])]\n",
        "          face_trackers[fid] = create_new_tracker(fid, frame, loc)\n",
        "          num_of_zeros = 3 - len(str(fid))\n",
        "\n",
        "          verified_identity = row['Identity']\n",
        "          if not pd.notnull(verified_identity):\n",
        "              face_names[row['faceID']] = {\n",
        "                  'name': '{person_id}'.format(person_id=num_of_zeros * '0' + str(fid)),\n",
        "                  'detected': False\n",
        "              }\n",
        "          else:\n",
        "              face_names[fid] = {\n",
        "                  'name': verified_identity,\n",
        "                  'dir': '{person_id}'.format(person_id=verified_identity + '/' + num_of_zeros * '0' + str(fid)),\n",
        "                  'detected': True\n",
        "              }\n",
        "\n",
        "    # Path to video file\n",
        "    start = time.time()\n",
        "    vidObj = cv2.VideoCapture(path)\n",
        "    # Get frame/second of the video\n",
        "    frames_per_second = int(vidObj.get(cv2.CAP_PROP_FPS))\n",
        "    length = vidObj.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "    \n",
        "    # vidObj.set(start_frame, length)\n",
        "    vidObj.set(1, start_frame)\n",
        "    end = time.time()\n",
        "    print('DecodeTime:', end - start)\n",
        "    print('Frames/second:', frames_per_second)\n",
        "    print('Total numer of frames:', length)\n",
        "\n",
        "    if desired_time is None:\n",
        "        frame_threshold = int(vidObj.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    else:\n",
        "        frame_threshold = int(desired_time * 60 * frames_per_second)\n",
        "\n",
        "    number_of_all_frames_digits = len(str(frame_threshold))\n",
        "\n",
        "\n",
        "    # while vidObj.isOpened() and frame_counter < frame_threshold:\n",
        "    for frame_counter in tqdm(range(start_frame+1, frame_threshold+1), desc='Loading'):\n",
        "        # vidObj object calls read\n",
        "        # function extract frames\n",
        "        start = time.time()\n",
        "        success, image = vidObj.read()\n",
        "        elapsed_decode_time.append(time.time() - start)\n",
        "\n",
        "        # if frame_counter > start_frame:\n",
        "        #   print(success)\n",
        "\n",
        "        # if success and frame_counter > start_frame :\n",
        "        if success:\n",
        "            # resize_frame = cv2.resize(image, (1280, 720), fx=0, fy=0, interpolation=cv2.INTER_CUBIC)\n",
        "            start = time.time()\n",
        "            resize_frame = image\n",
        "            face_trackers = check_tracker_quality(face_trackers, resize_frame,\n",
        "                                                  quality_thresh_hold=detection_quality_tsh, frame_num=frame_counter)\n",
        "            elapsed_checkquality_time.append(time.time() - start)\n",
        "\n",
        "            # Every 10 frames, we will have to determine which faces#### is that 10 frames or face_detection_tsh times\n",
        "            # are present in the frame\n",
        "            if (frame_counter % face_detection_tsh) == 0:\n",
        "                start = time.time()\n",
        "                # all_faces = RetinaFace.detect_faces(resize_frame)\n",
        "                all_faces = detection_model.predict_jsons(resize_frame)\n",
        "                # print(all_faces)\n",
        "                elapsed_detection_time.append(time.time() - start)\n",
        "\n",
        "                if len(all_faces) > 0:\n",
        "                    start = time.time()\n",
        "                    current_face_id, face_trackers = check_existence_of_new_faces(all_faces, face_trackers,\n",
        "                                                                                  face_names,\n",
        "                                                                                  resize_frame, current_face_id, frame_counter)\n",
        "                    elapsed_checkForNewTracker_time.append(time.time() - start)\n",
        "\n",
        "            # frame_counter += 1\n",
        "            start = time.time()\n",
        "            plot_image_with_boxes(resize_frame, face_trackers, face_names, number_of_all_frames_digits,\n",
        "                                  start_frame + frame_counter, output_file_name, face_shapes=resize_faces_shape, save_image=save_image)\n",
        "            elapsed_faceExtraction_time.append(time.time() - start)\n",
        "          \n",
        "            if os.path.isdir(framePath):\n",
        "              # df.iloc[0]['frameCounter'] = frame_counter\n",
        "              df.iloc[0, -1] = frame_counter              \n",
        "              df.to_csv(runInfoAddr, encoding='utf-8')\n",
        "            if show_result:\n",
        "                cv2.imshow('Face-Tracking', resize_frame)\n",
        "                # Press Q on keyboard to  exit\n",
        "                if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "                    break\n",
        "\n",
        "        elif (not success) or (frame_counter == frame_threshold):\n",
        "            vidObj.release()\n",
        "\n",
        "    if show_result:\n",
        "        # Destroy any OpenCV windows and exit the application\n",
        "        cv2.destroyAllWindows()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFq_YCZQVp4Z"
      },
      "source": [
        "def loadFromYT(link, name, output):\n",
        "  # link = 'https://www.youtube.com/watch?v=o8tXSiKW-h8'\n",
        "  try:\n",
        "    yt = YouTube(link)\n",
        "    stream = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()\n",
        "    stream.download(filename=name, output_path=output)\n",
        "  except RegexMatchError:\n",
        "    # 137: 1080p\n",
        "    # 136: 720p\n",
        "    # 135: 480p\n",
        "    # 134: 360p\n",
        "    # 133: 240\n",
        "    ydl_opts = {\n",
        "      # 'format': 'bestvideo/best',\n",
        "      'format':'136',\n",
        "      'outtmpl': f'{output}/{name}',\n",
        "      }\n",
        "    with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([link])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d2cUCXDzd_s"
      },
      "source": [
        "# Download The Face Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r7_kD4p5Tva"
      },
      "source": [
        "# import shutil\n",
        "\n",
        "# shutil.rmtree('frames')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMlr9q7vukH5",
        "outputId": "3407dcfb-e5b5-468f-eadc-9f98285bf005"
      },
      "source": [
        "\n",
        "# !apt install subversion\n",
        "!npx degit https://github.com/arashHarirpoosh/FaceRecognition/FaceDataBase FaceDataBase --force\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 1 in 2.321s\n",
            "\u001b[36m> cloned \u001b[1marashHarirpoosh/FaceRecognition\u001b[22m#\u001b[1mHEAD\u001b[22m to FaceDataBase\u001b[39m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYKXCRF5bB2b"
      },
      "source": [
        "#Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQ8ygWKDbAKC",
        "outputId": "2342b36f-555d-4512-bd75-e1ad27607902"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    print('dlib version:', dlib.__version__)\n",
        "\n",
        "    elapsed_decode_time = []\n",
        "    elapsed_detection_time = []\n",
        "    elapsed_checkquality_time = []\n",
        "    elapsed_checkForNewTracker_time = []\n",
        "    elapsed_faceExtraction_time = []\n",
        "    elapsed_verification_time = []\n",
        "\n",
        "\n",
        "    model = DeepFace.build_model('ArcFace')\n",
        "    \n",
        "    detection_model = get_model(\"resnet50_2020-07-20\", max_size=2048)\n",
        "    detection_model.eval()\n",
        "\n",
        "    base_addr = 'Videos'\n",
        "\n",
        "    # num_of_sources = len(os.listdir(base_addr))\n",
        "    # source_digits = len(str(num_of_sources))\n",
        "    source_digits = 3\n",
        "\n",
        "    # selected_channels = ['1', '2']\n",
        "    selected_channels = ['1']\n",
        "    selected_videos = [3]\n",
        "    # 1:CNN, 2:BBC\n",
        "    # videos = {\n",
        "    #     '1':\n",
        "    #           {\n",
        "    #               # '1': 'https://www.youtube.com/watch?v=CmCp6Z54GYU',\n",
        "    #               # '2':'https://youtu.be/pJlnxbO5N2g',\n",
        "    #               # '3':'https://youtu.be/e0sGuSaGvV0',\n",
        "    #               # '4': 'https://youtu.be/ZO_UqxwasO4',\n",
        "    #               # '5':'https://youtu.be/fx2W1Jh4kA0',\n",
        "    #               '6': 'https://www.youtube.com/watch?v=6y877A9IA4U',\n",
        "    #               # '7':'https://www.youtube.com/watch?v=Rli9ZRvemh0',\n",
        "    #               # '8':'https://www.youtube.com/watch?v=cQAH7d-k068',\n",
        "    #               # '9':'https://www.youtube.com/watch?v=dG7ya0Iq8U0',\n",
        "    #               # '10':'https://www.youtube.com/watch?v=Slu4WdZKq0A',\n",
        "    #               # '11':'https://www.youtube.com/watch?v=nt5iBZCgqvs',\n",
        "    #               # '12':'https://www.youtube.com/watch?v=X59GyNfVFeM',\n",
        "\n",
        "\n",
        "    #           }\n",
        "    #     # '2':\n",
        "    #     #       {\n",
        "    #     #           '1':'https://www.youtube.com/watch?v=sXQLYOHihUg',\n",
        "                  \n",
        "    #     #       }\n",
        "    # }\n",
        "    \n",
        "    with open('drive/MyDrive/videos.json') as json_file:\n",
        "      videos = json.load(json_file)\n",
        "\n",
        "    for channels, videos in videos.items():\n",
        "        file_digits = 4\n",
        "        # root = 'Videos/{c}'.format(c=channels)\n",
        "        root = 'drive/MyDrive/Videos/{c}'.format(c=channels)\n",
        "        for file_number, link in videos.items():\n",
        "          if int(file_number) in selected_videos:\n",
        "            file_name = file_number+'.mp4'\n",
        "            if not os.path.isfile(root + '/' + file_name):\n",
        "              loadFromYT(link=link, name=file_name, output=root)\n",
        "\n",
        "            root_list = root.split('/')\n",
        "            # root_list[-2] = 'drive/MyDrive/Frames'\n",
        "            root_list[-2] = 'Frames'\n",
        "            source_number = root_list[-1]\n",
        "            root_list[-1] = (source_digits - len(source_number)) * '0' + source_number\n",
        "            root_list.append((file_digits - len(file_number)) * '0' + file_number)\n",
        "            p = f'{root}/{file_name}'\n",
        "\n",
        "            runInfoAddr = '/'.join(root_list) + '/runInfo.csv'\n",
        "            columns = [\n",
        "                         'faceID',\n",
        "                         'Identity',\n",
        "                         'StartFrame',\n",
        "                         'LastFrame',\n",
        "                         'loc_x',\n",
        "                         'loc_y',\n",
        "                         'loc_w',\n",
        "                         'loc_h',\n",
        "                         'frameCounter'\n",
        "              ]\n",
        "            if os.path.isfile(runInfoAddr):\n",
        "              df = pd.read_csv(runInfoAddr, usecols=columns)\n",
        "              # dtypes = {\n",
        "              #            'faceID':int,\n",
        "              #            'Identity':str,\n",
        "              #            'StartFrame':int,\n",
        "              #            'LastFrame':int,\n",
        "              #            'loc_x':int,\n",
        "              #            'loc_y':int,\n",
        "              #            'loc_w':int,\n",
        "              #            'loc_h':int,\n",
        "              #            'frameCounter':int\n",
        "              # }\n",
        "              # for col, dtype in dtypes.items():\n",
        "              #   df[col] = df[col].astype(dtype)\n",
        "            else:\n",
        "\n",
        "              df = pd.DataFrame(columns=columns)\n",
        "            \n",
        "            print(p)\n",
        "            print(root_list)\n",
        "\n",
        "            start_time = time.time()\n",
        "            face_tracking(\n",
        "                path=p,\n",
        "                output_file_name=root_list,\n",
        "                detection_quality_tsh=7,\n",
        "                face_detection_tsh=20,\n",
        "                # resize_faces_shape=(300, 400),\n",
        "                resize_faces_shape=None,\n",
        "                save_image=True,\n",
        "                show_result=False,\n",
        "                # desired_time=1,\n",
        "                # start_frame=8954,\n",
        "                # current_face_id = 155\n",
        "            )\n",
        "\n",
        "            elapsed_time = time.time() - start_time\n",
        "            time_report = f'Finished in {elapsed_time} seconds, or {elapsed_time / 60} minutes'\n",
        "            print(time_report)\n",
        "            file = open(r\"{folder}/time.txt\".format(folder='/'.join(root_list)), \"w+\")\n",
        "            file.write(time_report)\n",
        "            file.close()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dlib version: 19.18.0\n",
            "drive/MyDrive/Videos/1/3.mp4\n",
            "['drive', 'MyDrive', 'Frames', '001', '0003']\n",
            "DecodeTime: 0.0554046630859375\n",
            "Frames/second: 29\n",
            "Total numer of frames: 18979.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading:   0%|          | 16/18979 [00:11<02:01, 155.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new tracker 1\n",
            "Creating new tracker 2\n",
            "Creating new tracker 3\n",
            "Already built model is passed\n",
            "retinaface.h5 will be downloaded from the url https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n",
            "To: /root/.deepface/weights/retinaface.h5\n",
            "\n",
            "  0%|          | 0.00/119M [00:00<?, ?B/s]\u001b[A\n",
            "  9%|▉         | 10.5M/119M [00:00<00:01, 104MB/s]\u001b[A\n",
            " 18%|█▊        | 21.0M/119M [00:00<00:01, 62.2MB/s]\u001b[A\n",
            " 32%|███▏      | 37.7M/119M [00:00<00:00, 81.3MB/s]\u001b[A\n",
            " 46%|████▌     | 54.5M/119M [00:00<00:00, 104MB/s] \u001b[A\n",
            " 56%|█████▌    | 66.1M/119M [00:00<00:00, 86.8MB/s]\u001b[A\n",
            " 64%|██████▍   | 76.0M/119M [00:01<00:00, 67.1MB/s]\u001b[A\n",
            " 80%|███████▉  | 94.4M/119M [00:01<00:00, 71.6MB/s]\u001b[A\n",
            " 87%|████████▋ | 103M/119M [00:01<00:00, 74.3MB/s] \u001b[A\n",
            "100%|██████████| 119M/119M [00:01<00:00, 68.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Representations stored in  /content/FaceDataBase / representations_arcface.pkl  file. Please delete this file when you add new identities in your database.\n",
            "find function lasts  99.89003705978394  seconds\n",
            "Empty DataFrame\n",
            "Columns: [identity, ArcFace_euclidean_l2]\n",
            "Index: []\n",
            "\n",
            "No Face Detected\n",
            "Already built model is passed\n",
            "WARNING: Representations for images in  /content/FaceDataBase  folder were previously stored in  representations_arcface.pkl . If you added new instances after this file creation, then please delete this file and call find function again. It will create it again.\n",
            "There are  43  representations found in  representations_arcface.pkl\n",
            "find function lasts  2.6472487449645996  seconds\n",
            "Empty DataFrame\n",
            "Columns: [identity, ArcFace_euclidean_l2]\n",
            "Index: []\n",
            "\n",
            "No Face Detected\n",
            "Already built model is passed\n",
            "WARNING: Representations for images in  /content/FaceDataBase  folder were previously stored in  representations_arcface.pkl . If you added new instances after this file creation, then please delete this file and call find function again. It will create it again.\n",
            "There are  43  representations found in  representations_arcface.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading:   0%|          | 22/18979 [02:10<38:09:00,  7.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "find function lasts  2.326418876647949  seconds\n",
            "Empty DataFrame\n",
            "Columns: [identity, ArcFace_euclidean_l2]\n",
            "Index: []\n",
            "\n",
            "No Face Detected\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading:   0%|          | 66/18979 [03:04<7:50:38,  1.49s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing tracker 2 from list of trackers\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading:   0%|          | 77/18979 [03:21<1:37:49,  3.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new tracker 4\n",
            "Already built model is passed\n",
            "WARNING: Representations for images in  /content/FaceDataBase  folder were previously stored in  representations_arcface.pkl . If you added new instances after this file creation, then please delete this file and call find function again. It will create it again.\n",
            "There are  43  representations found in  representations_arcface.pkl\n",
            "find function lasts  1.888580083847046  seconds\n",
            "Empty DataFrame\n",
            "Columns: [identity, ArcFace_euclidean_l2]\n",
            "Index: []\n",
            "\n",
            "No Face Detected\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading:   1%|          | 179/18979 [05:23<1:03:54,  4.90it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH5jW0j1ZJIU",
        "outputId": "4c9cc353-f067-4093-c48e-8fb803d79b2e"
      },
      "source": [
        "    print(f'Decode Time:\\n Mean: {np.mean(elapsed_decode_time)} seconds,\\n All: {np.sum(elapsed_decode_time)/60.0} mins')\n",
        "    print(f'Detection Time:\\n Mean: {np.mean(elapsed_detection_time)} seconds,\\n All: {np.sum(elapsed_detection_time)/60.0} mins')\n",
        "    print(f'Time For Checking Quality Of Trackers:\\n Mean: {np.mean(elapsed_checkquality_time)} seconds,\\n All: {np.sum(elapsed_checkquality_time)/60.0} mins')\n",
        "    print(f'Time For Checking For New Trackers:\\n Mean: {np.mean(elapsed_checkForNewTracker_time)} seconds,\\n All: {np.sum(elapsed_checkForNewTracker_time)/60.0} mins')\n",
        "    print(f'Time For Labelling And Saving Faces:\\n Mean: {np.mean(elapsed_faceExtraction_time)} seconds,\\n All: {np.sum(elapsed_faceExtraction_time)/60.0} mins')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decode Time:\n",
            " Mean: 0.002061899503072103 seconds,\n",
            " All: 0.05979508558909098 mins\n",
            "Detection Time:\n",
            " Mean: 24.527051681695983 seconds,\n",
            " All: 17.57772037188212 mins\n",
            "Time For Checking Quality Of Trackers:\n",
            " Mean: 0.029441905432733995 seconds,\n",
            " All: 0.8538152575492859 mins\n",
            "Time For Checking For New Trackers:\n",
            " Mean: 0.007171736207119254 seconds,\n",
            " All: 0.005139744281768799 mins\n",
            "Time For Labelling And Saving Faces:\n",
            " Mean: 0.014532128969828287 seconds,\n",
            " All: 0.4214317401250203 mins\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31Ge4bd4rCE5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}