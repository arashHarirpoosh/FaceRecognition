{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RetinaFaceTracker_retinaface_pytorch_lib.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "OMGW_3GxZweU",
        "8d2cUCXDzd_s"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arashHarirpoosh/FaceRecognition/blob/main/RetinaFaceTracker_retinaface_pytorch_lib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2OVpq8Xrg74"
      },
      "source": [
        "# Import lib's"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4o4dKRX9Vbjx",
        "outputId": "c2bb864c-a304-4e2f-f9ce-53a872c61cf6"
      },
      "source": [
        "!pip install pytube\n",
        "!pip install --upgrade youtube-dl\n",
        "!pip install 'h5py==2.10.0' --force-reinstall\n",
        "# !pip install retinaface\n",
        "!pip install deepface\n",
        "!pip install -U retinaface_pytorch > /dev/null"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-11.0.1-py3-none-any.whl (56 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▉                          | 10 kB 24.7 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 20 kB 26.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 30 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 40 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 56 kB 2.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-11.0.1\n",
            "Collecting youtube-dl\n",
            "  Downloading youtube_dl-2021.6.6-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 5.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: youtube-dl\n",
            "Successfully installed youtube-dl-2021.6.6\n",
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 5.4 MB/s \n",
            "\u001b[?25hCollecting six\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting numpy>=1.7\n",
            "  Downloading numpy-1.21.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 198 kB/s \n",
            "\u001b[?25hInstalling collected packages: six, numpy, h5py\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.6.0 requires h5py~=3.1.0, but you have h5py 2.10.0 which is incompatible.\n",
            "tensorflow 2.6.0 requires numpy~=1.19.2, but you have numpy 1.21.2 which is incompatible.\n",
            "tensorflow 2.6.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed h5py-2.10.0 numpy-1.21.2 six-1.16.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepface\n",
            "  Downloading deepface-0.0.68-py3-none-any.whl (61 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▍                          | 10 kB 16.2 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 20 kB 21.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 30 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 40 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 51 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (2.6.0)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (7.1.2)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (2.6.0)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.7/dist-packages (from deepface) (1.1.5)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from deepface) (1.1.4)\n",
            "Requirement already satisfied: opencv-python>=3.4.4 in /usr/local/lib/python3.7/dist-packages (from deepface) (4.1.2.30)\n",
            "Collecting retina-face>=0.0.1\n",
            "  Downloading retina_face-0.0.5-py3-none-any.whl (14 kB)\n",
            "Collecting mtcnn>=0.1.0\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 13.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (1.21.2)\n",
            "Collecting gdown>=3.10.1\n",
            "  Downloading gdown-4.0.2.tar.gz (10 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->deepface) (7.1.2)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->deepface) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->deepface) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->deepface) (1.1.0)\n",
            "Requirement already satisfied: requests[socks]>=2.12.0 in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->deepface) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->deepface) (3.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->deepface) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=1.1.2->deepface) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.4->deepface) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.12.0->gdown>=3.10.1->deepface) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.12.0->gdown>=3.10.1->deepface) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.12.0->gdown>=3.10.1->deepface) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.12.0->gdown>=3.10.1->deepface) (2021.5.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.12.0->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.12)\n",
            "Collecting six\n",
            "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (3.7.4.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (2.6.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (3.3.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.41.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.12.1)\n",
            "Collecting h5py~=3.1.0\n",
            "  Downloading h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 33.6 MB/s \n",
            "\u001b[?25hCollecting numpy>=1.14.0\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 156 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (0.37.0)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (5.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (2.6.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (3.17.3)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (0.4.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=1.9.0->deepface) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (0.4.6)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (3.6.0)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-4.0.2-py3-none-any.whl size=10613 sha256=8e426e105875250f72377a2fdbccca058d8522e5c4ae2a34a0d2cdfd7a8ceeca\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/20/08/4d138cf98df8fe9e14e369c7de79e01c5cabca55b0f58cef3a\n",
            "Successfully built gdown\n",
            "Installing collected packages: six, numpy, h5py, gdown, retina-face, mtcnn, deepface\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.2\n",
            "    Uninstalling numpy-1.21.2:\n",
            "      Successfully uninstalled numpy-1.21.2\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 2.10.0\n",
            "    Uninstalling h5py-2.10.0:\n",
            "      Successfully uninstalled h5py-2.10.0\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 3.6.4\n",
            "    Uninstalling gdown-3.6.4:\n",
            "      Successfully uninstalled gdown-3.6.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed deepface-0.0.68 gdown-4.0.2 h5py-3.1.0 mtcnn-0.1.1 numpy-1.19.5 retina-face-0.0.5 six-1.15.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.20 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.4.1 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.28.0 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY_wFD3waS6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e50fd4a4-9ac4-49c4-8d49-a97bc3db87d5"
      },
      "source": [
        "# !rm ./*jpg\n",
        "# %rm -rf drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove './*jpg': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TvTE0WoVlYV"
      },
      "source": [
        "from pytube import YouTube\n",
        "from pytube.exceptions import RegexMatchError\n",
        "import youtube_dl\n",
        "import dlib\n",
        "# from retinaface import RetinaFace\n",
        "from deepface import DeepFace\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "import cv2\n",
        "import os\n",
        "import threading\n",
        "import time\n",
        "import torch\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "from retinaface.pre_trained_models import get_model\n",
        "from retinaface.utils import vis_annotations\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwMP93nlXdTY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecb1564b-4c78-4378-86f6-beb81e7afc05"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMGW_3GxZweU"
      },
      "source": [
        "#Codes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODNBIwBaWOfL"
      },
      "source": [
        "def check_tracker_quality(face_trackers, base_image, quality_thresh_hold=7):\n",
        "    # Update all the trackers and remove the ones for which the update\n",
        "    # indicated the quality was not good enough\n",
        "    fids_to_delete = []\n",
        "    for fid in face_trackers.keys():\n",
        "        trackingQuality = face_trackers[fid].update(base_image)\n",
        "\n",
        "        # If the tracking quality is good enough, we must delete\n",
        "        # this tracker\n",
        "        if trackingQuality < quality_thresh_hold:\n",
        "            fids_to_delete.append(fid)\n",
        "\n",
        "    for fid in fids_to_delete:\n",
        "        print(\"Removing tracker \" + str(fid) + \" from list of trackers\")\n",
        "        del face_trackers[fid]\n",
        "    return face_trackers\n",
        "\n",
        "\n",
        "def create_new_tracker(current_face_id, frame, loc):\n",
        "    print(\"Creating new tracker \" + str(current_face_id))\n",
        "\n",
        "    x, y, w, h = loc\n",
        "    # Create and store the tracker\n",
        "    tracker = dlib.correlation_tracker()\n",
        "    tracker.start_track(frame,\n",
        "                        dlib.rectangle(x - int(w / 4),\n",
        "                                       y - int(h / 4),\n",
        "                                       x + w + int(w / 4),\n",
        "                                       y + h + int(h / 4)))\n",
        "    return tracker"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeOW3WBSZ5bE"
      },
      "source": [
        "def do_recognize_person(face_names, fid, face_img):\n",
        "    verified_identity = None\n",
        "    try:\n",
        "        face_img_bgr = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
        "        df = DeepFace.find(face_img_bgr,\n",
        "                           db_path=\"/content/FaceDataBase\",\n",
        "                           enforce_detection=False,\n",
        "                           detector_backend='retinaface',\n",
        "                           model_name='ArcFace',\n",
        "                           model=model,\n",
        "                           distance_metric=\"euclidean_l2\")\n",
        "        print(df)\n",
        "        print()\n",
        "        # filtered_faced = df[df['ArcFace_euclidean_l2'] <= 1]\n",
        "        closest_identity = df.loc[df['ArcFace_euclidean_l2'].idxmin()]\n",
        "        print(closest_identity['identity'])\n",
        "        # verified_identity = closest_identity['identity'].split('/')[-2].split('\\\\')[1]\n",
        "        verified_identity = closest_identity['identity'].split('/')[-2]\n",
        "\n",
        "        print()\n",
        "        print(verified_identity)\n",
        "        del df\n",
        "        gc.collect()\n",
        "    except (ValueError, cv2.error):\n",
        "        gc.collect()\n",
        "        print('No Face Detected')\n",
        "        # all_faces = RetinaFace.detect_faces(data)\n",
        "        # print(all_faces)\n",
        "        # cv2.imshow('face', face_img)\n",
        "        # cv2.waitKey()\n",
        "\n",
        "    num_of_zeros = 3 - len(str(fid))\n",
        "    if verified_identity is None:\n",
        "        face_names[fid] = {\n",
        "            'name': '{person_id}'.format(person_id=num_of_zeros * '0' + str(fid)),\n",
        "            'detected': False\n",
        "        }\n",
        "    else:\n",
        "        face_names[fid] = {\n",
        "            'name': verified_identity,\n",
        "            'dir': '{person_id}'.format(person_id=verified_identity + '/' + num_of_zeros * '0' + str(fid)),\n",
        "            'detected': True\n",
        "        }\n",
        "\n",
        "\n",
        "def check_existence_of_new_faces(result_list, face_trackers,\n",
        "                                 face_names, frame, current_face_id):\n",
        "    verified_trackers = []\n",
        "    for result in result_list:\n",
        "        x, y, x1, y1 = result['bbox']\n",
        "        w, h = abs(x1 - x), abs(y1 - y)\n",
        "\n",
        "        # Calculate the center point\n",
        "        x_bar = (x + x1) / 2\n",
        "        y_bar = (y + y1) / 2\n",
        "\n",
        "        # Variable holding information which faceid we\n",
        "        # matched with\n",
        "        matched_fid = None\n",
        "\n",
        "        # Now loop over all the trackers and check if the\n",
        "        # center point of the face is within the box of a\n",
        "        # tracker\n",
        "        for fid in face_trackers.keys():\n",
        "            tracked_position = face_trackers[fid].get_position()\n",
        "            t_x = int(tracked_position.left())\n",
        "            t_y = int(tracked_position.top())\n",
        "            t_w = int(tracked_position.width())\n",
        "            t_h = int(tracked_position.height())\n",
        "\n",
        "            # calculate the center point\n",
        "            t_x_bar = t_x + 0.5 * t_w\n",
        "            t_y_bar = t_y + 0.5 * t_h\n",
        "\n",
        "            # check if the center point of the face is within the\n",
        "            # rectangle of a tracker region. Also, the center point\n",
        "            # of the tracker region must be within the region\n",
        "            # detected as a face. If both of these conditions hold\n",
        "            # we have a match\n",
        "            if ((t_x <= x_bar <= (t_x + t_w)) and\n",
        "                    (t_y <= y_bar <= (t_y + t_h)) and\n",
        "                    (x <= t_x_bar <= (x + w)) and\n",
        "                    (y <= t_y_bar <= (y + h))):\n",
        "                matched_fid = fid\n",
        "                verified_trackers.append(fid)\n",
        "\n",
        "        if matched_fid is None:\n",
        "            loc = [x, y, w, h]\n",
        "            tracker = create_new_tracker(current_face_id, frame, loc)\n",
        "\n",
        "            face_trackers[current_face_id] = tracker\n",
        "            verified_trackers.append(current_face_id)\n",
        "            # Start a new thread that is used to simulate\n",
        "            # face recognition. This is not yet implemented in this\n",
        "            # version :)\n",
        "            # t = threading.Thread(target=do_recognize_person,\n",
        "            #                      args=(face_names, current_face_id))\n",
        "            # t.start()\n",
        "            # Increase the currentFaceID counter\n",
        "            current_face_id += 1\n",
        "\n",
        "    # Remove the trackers that are not in the second detection\n",
        "    all_fids = face_trackers.copy().keys()\n",
        "    for fid in all_fids:\n",
        "        if fid not in verified_trackers:\n",
        "            print(\"Removing tracker \" + str(fid) +\n",
        "                  \" from list of trackers because of not appearing in the second detection\")\n",
        "            del face_trackers[fid]\n",
        "    del all_fids\n",
        "            \n",
        "    return current_face_id, face_trackers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3j-hgcLZ-pU"
      },
      "source": [
        "def plot_image_with_boxes(frame, face_trackers, face_name, num_of_digits,\n",
        "                          frame_number, output_file_name, face_shapes=None, save_image=True):\n",
        "    face_img = frame.copy()\n",
        "    for fid in face_trackers.keys():\n",
        "        tracked_position = face_trackers[fid].get_position()\n",
        "        t_x = int(tracked_position.left())\n",
        "        t_y = int(tracked_position.top())\n",
        "        t_w = int(tracked_position.width())\n",
        "        t_h = int(tracked_position.height())\n",
        "\n",
        "        # face = frame[t_y:t_y + t_h, t_x:t_x + t_w]\n",
        "        face = face_img[t_y:t_y + t_h, t_x:t_x + t_w]\n",
        "        if face_shapes is not None:\n",
        "            face = cv2.resize(face, face_shapes, fx=0, fy=0, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "        if fid in face_name.keys():\n",
        "            box_name = face_name[fid]['name']\n",
        "\n",
        "        else:\n",
        "            box_name = 'Detecting...'\n",
        "            start = time.time()\n",
        "            do_recognize_person(face_name, fid, face)\n",
        "            elapsed_verification_time.append(time.time() - start)\n",
        "        if save_image:\n",
        "            if face_name[fid]['detected']:\n",
        "                directory = '/'.join(output_file_name) + '/labeled/' + face_name[fid]['dir']\n",
        "                id_person = face_name[fid]['dir'].split('/')[1]\n",
        "            else:\n",
        "                directory = '/'.join(output_file_name) + '/unlabeled/' + face_name[fid]['name']\n",
        "                id_person = face_name[fid]['name']\n",
        "            # directory = output_file_name + '\\\\unlabeled\\\\' + face_name[fid]\n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "\n",
        "            num_of_zeros = num_of_digits - len(str(frame_number))\n",
        "            img_name = directory + '/{source}_{n_video}_{frameNumber}_{id_p}_{x}_{y}_{h}_{w}.jpg'.format(\n",
        "                source=output_file_name[-2], n_video=output_file_name[-1]\n",
        "                , frameNumber=num_of_zeros * '0' + str(frame_number)\n",
        "                , id_p=id_person, x=t_x, y=t_y, h=t_h, w=t_w)\n",
        "\n",
        "            try:\n",
        "                cv2.imwrite(img_name, face)\n",
        "            except cv2.error:\n",
        "                pass\n",
        "\n",
        "        cv2.rectangle(frame, (t_x, t_y),\n",
        "                      (t_x + t_w, t_y + t_h),\n",
        "                      (0, 0, 255), 2)\n",
        "        cv2.putText(frame, box_name, (int(t_x + t_w / 2), int(t_y)),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    0.5, (204, 204, 0), 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBLkYTH4aCgi"
      },
      "source": [
        "\n",
        "def face_tracking(path, output_file_name, detection_quality_tsh=7, save_image=True, show_result=True,\n",
        "                  face_detection_tsh=10, resize_faces_shape=None, desired_time=None, start_frame=0, current_face_id=1):\n",
        "    # Path to video file\n",
        "    start = time.time()\n",
        "    vidObj = cv2.VideoCapture(path)\n",
        "    # Get frame/second of the video\n",
        "    frames_per_second = int(vidObj.get(cv2.CAP_PROP_FPS))\n",
        "    length = vidObj.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "\n",
        "    if desired_time is None:\n",
        "        frame_threshold = int(vidObj.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    else:\n",
        "        frame_threshold = int(desired_time * 60 * frames_per_second)\n",
        "    \n",
        "    # vidObj.set(start_frame, length)\n",
        "    vidObj.set(1, start_frame)\n",
        "    end = time.time()\n",
        "    print('DecodeTime:', end - start)\n",
        "    print('Frames/second:', frames_per_second)\n",
        "    print('Total numer of frames:', length)\n",
        "\n",
        "\n",
        "    if show_result:\n",
        "        cv2.namedWindow(\"Face-Tracking\", cv2.WINDOW_AUTOSIZE)  ###make window for image or video\n",
        "\n",
        "        # Start the window thread for the two windows we are using\n",
        "        cv2.startWindowThread()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    number_of_all_frames_digits = len(str(frame_threshold))\n",
        "\n",
        "    # Used as counter variable\n",
        "    frame_counter = 0\n",
        "    # current_face_id = 1\n",
        "\n",
        "    # Variables holding the correlation trackers and the name per faceid\n",
        "    face_trackers = {}\n",
        "    face_names = {}\n",
        "\n",
        "    # while vidObj.isOpened() and frame_counter < frame_threshold:\n",
        "    for frame_counter in tqdm(range(1, frame_threshold+1), desc='Loading'):\n",
        "        # vidObj object calls read\n",
        "        # function extract frames\n",
        "        start = time.time()\n",
        "        success, image = vidObj.read()\n",
        "        elapsed_decode_time.append(time.time() - start)\n",
        "\n",
        "        # if frame_counter > start_frame:\n",
        "        #   print(success)\n",
        "\n",
        "        # if success and frame_counter > start_frame :\n",
        "        if success:\n",
        "            # resize_frame = cv2.resize(image, (1280, 720), fx=0, fy=0, interpolation=cv2.INTER_CUBIC)\n",
        "            start = time.time()\n",
        "            resize_frame = image\n",
        "            face_trackers = check_tracker_quality(face_trackers, resize_frame,\n",
        "                                                  quality_thresh_hold=detection_quality_tsh)\n",
        "            elapsed_checkquality_time.append(time.time() - start)\n",
        "\n",
        "            # Every 10 frames, we will have to determine which faces#### is that 10 frames or face_detection_tsh times\n",
        "            # are present in the frame\n",
        "            if (frame_counter % face_detection_tsh) == 0:\n",
        "                start = time.time()\n",
        "                # all_faces = RetinaFace.detect_faces(resize_frame)\n",
        "                all_faces = detection_model.predict_jsons(resize_frame)\n",
        "                # print(all_faces)\n",
        "                elapsed_detection_time.append(time.time() - start)\n",
        "\n",
        "                if len(all_faces) > 0:\n",
        "                    start = time.time()\n",
        "                    current_face_id, face_trackers = check_existence_of_new_faces(all_faces, face_trackers,\n",
        "                                                                                  face_names,\n",
        "                                                                                  resize_frame, current_face_id)\n",
        "                    elapsed_checkForNewTracker_time.append(time.time() - start)\n",
        "\n",
        "            # frame_counter += 1\n",
        "            start = time.time()\n",
        "            plot_image_with_boxes(resize_frame, face_trackers, face_names, number_of_all_frames_digits,\n",
        "                                  start_frame + frame_counter, output_file_name, face_shapes=resize_faces_shape, save_image=save_image)\n",
        "            elapsed_faceExtraction_time.append(time.time() - start)\n",
        "            if show_result:\n",
        "                cv2.imshow('Face-Tracking', resize_frame)\n",
        "                # Press Q on keyboard to  exit\n",
        "                if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "                    break\n",
        "\n",
        "        elif (not success) or (frame_counter == frame_threshold):\n",
        "            vidObj.release()\n",
        "\n",
        "    if show_result:\n",
        "        # Destroy any OpenCV windows and exit the application\n",
        "        cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFq_YCZQVp4Z"
      },
      "source": [
        "def loadFromYT(link, name, output):\n",
        "  # link = 'https://www.youtube.com/watch?v=o8tXSiKW-h8'\n",
        "  try:\n",
        "    yt = YouTube(link)\n",
        "    stream = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()\n",
        "    stream.download(filename=name, output_path=output)\n",
        "  except RegexMatchError:\n",
        "    # 137: 1080p\n",
        "    # 136: 720p\n",
        "    # 135: 480p\n",
        "    # 134: 360p\n",
        "    # 133: 240\n",
        "    ydl_opts = {\n",
        "      # 'format': 'bestvideo/best',\n",
        "      'format':'136',\n",
        "      'outtmpl': f'{output}/{name}',\n",
        "      }\n",
        "    with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([link])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d2cUCXDzd_s"
      },
      "source": [
        "# Download The Face Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r7_kD4p5Tva"
      },
      "source": [
        "# import shutil\n",
        "\n",
        "# shutil.rmtree('frames')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMlr9q7vukH5",
        "outputId": "b49dd833-5361-4257-f84c-7085f05b3b53"
      },
      "source": [
        "\n",
        "# !apt install subversion\n",
        "!npx degit https://github.com/arashHarirpoosh/FaceRecognition/FaceDataBase FaceDataBase --force\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 1 in 2.445s\n",
            "\u001b[36m> cloned \u001b[1marashHarirpoosh/FaceRecognition\u001b[22m#\u001b[1mHEAD\u001b[22m to FaceDataBase\u001b[39m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYKXCRF5bB2b"
      },
      "source": [
        "#Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "qQ8ygWKDbAKC",
        "outputId": "3908af43-9246-408e-fe02-6b8508fe036c"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    print('dlib version:', dlib.__version__)\n",
        "\n",
        "    elapsed_decode_time = []\n",
        "    elapsed_detection_time = []\n",
        "    elapsed_checkquality_time = []\n",
        "    elapsed_checkForNewTracker_time = []\n",
        "    elapsed_faceExtraction_time = []\n",
        "    elapsed_verification_time = []\n",
        "\n",
        "\n",
        "    model = DeepFace.build_model('ArcFace')\n",
        "    \n",
        "    detection_model = get_model(\"resnet50_2020-07-20\", max_size=2048)\n",
        "    detection_model.eval()\n",
        "\n",
        "    base_addr = 'Videos'\n",
        "\n",
        "    # num_of_sources = len(os.listdir(base_addr))\n",
        "    # source_digits = len(str(num_of_sources))\n",
        "    source_digits = 3\n",
        "\n",
        "    # selected_channels = ['1', '2']\n",
        "    selected_channels = ['1']\n",
        "    selected_videos = [1]\n",
        "    # 1:CNN, 2:BBC\n",
        "    # videos = {\n",
        "    #     '1':\n",
        "    #           {\n",
        "    #               # '1': 'https://www.youtube.com/watch?v=CmCp6Z54GYU',\n",
        "    #               # '2':'https://youtu.be/pJlnxbO5N2g',\n",
        "    #               # '3':'https://youtu.be/e0sGuSaGvV0',\n",
        "    #               # '4': 'https://youtu.be/ZO_UqxwasO4',\n",
        "    #               # '5':'https://youtu.be/fx2W1Jh4kA0',\n",
        "    #               '6': 'https://www.youtube.com/watch?v=6y877A9IA4U',\n",
        "    #               # '7':'https://www.youtube.com/watch?v=Rli9ZRvemh0',\n",
        "    #               # '8':'https://www.youtube.com/watch?v=cQAH7d-k068',\n",
        "    #               # '9':'https://www.youtube.com/watch?v=dG7ya0Iq8U0',\n",
        "    #               # '10':'https://www.youtube.com/watch?v=Slu4WdZKq0A',\n",
        "    #               # '11':'https://www.youtube.com/watch?v=nt5iBZCgqvs',\n",
        "    #               # '12':'https://www.youtube.com/watch?v=X59GyNfVFeM',\n",
        "\n",
        "\n",
        "    #           }\n",
        "    #     # '2':\n",
        "    #     #       {\n",
        "    #     #           '1':'https://www.youtube.com/watch?v=sXQLYOHihUg',\n",
        "                  \n",
        "    #     #       }\n",
        "    # }\n",
        "    \n",
        "    with open('videos.json') as json_file:\n",
        "      videos = json.load(json_file)\n",
        "\n",
        "    for channels, videos in videos.items():\n",
        "        file_digits = 4\n",
        "        # root = 'Videos/{c}'.format(c=channels)\n",
        "        root = 'drive/MyDrive/Videos/{c}'.format(c=channels)\n",
        "        for file_number, link in videos.items():\n",
        "          file_name = file_number+'.mp4'\n",
        "          if not os.path.isfile(root + '/' + file_name):\n",
        "            loadFromYT(link=link, name=file_name, output=root)\n",
        "          root_list = root.split('/')\n",
        "          # root_list[-2] = 'drive/MyDrive/Frames'\n",
        "          root_list[-2] = 'Frames'\n",
        "          source_number = root_list[-1]\n",
        "          root_list[-1] = (source_digits - len(source_number)) * '0' + source_number\n",
        "          root_list.append((file_digits - len(file_number)) * '0' + file_number)\n",
        "          p = f'{root}/{file_name}'\n",
        "          \n",
        "          print(p)\n",
        "          print(root_list)\n",
        "\n",
        "          start_time = time.time()\n",
        "          face_tracking(\n",
        "              path=p,\n",
        "              output_file_name=root_list,\n",
        "              detection_quality_tsh=7,\n",
        "              face_detection_tsh=20,\n",
        "              # resize_faces_shape=(300, 400),\n",
        "              resize_faces_shape=None,\n",
        "              save_image=True,\n",
        "              show_result=False,\n",
        "              # desired_time=1,\n",
        "              # start_frame=1748,\n",
        "              # current_face_id = 27\n",
        "          )\n",
        "\n",
        "          elapsed_time = time.time() - start_time\n",
        "          time_report = f'Finished in {elapsed_time} seconds, or {elapsed_time / 60} minutes'\n",
        "          print(time_report)\n",
        "          file = open(r\"{folder}/time.txt\".format(folder='/'.join(root_list)), \"w+\")\n",
        "          file.write(time_report)\n",
        "          file.close()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dlib version: 19.18.0\n",
            "False\n",
            "drive/MyDrive/Videos/1/1.mp4\n",
            "['drive', 'MyDrive', 'drive/MyDrive/Frames', '01', '001']\n",
            "DecodeTime: 0.03322744369506836\n",
            "Frames/second: 29\n",
            "Total numer of frames: 14458.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading:   0%|          | 39/14458 [00:05<33:09,  7.25it/s] \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-0e295d8431f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m               \u001b[0mresize_faces_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m               \u001b[0msave_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m               \u001b[0mshow_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m               \u001b[0;31m# desired_time=1,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m               \u001b[0;31m# start_frame=1748,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-3bd3c0432169>\u001b[0m in \u001b[0;36mface_tracking\u001b[0;34m(path, output_file_name, detection_quality_tsh, save_image, show_result, face_detection_tsh, resize_faces_shape, desired_time, start_frame, current_face_id)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0;31m# all_faces = RetinaFace.detect_faces(resize_frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0mall_faces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetection_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_jsons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresize_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m                 \u001b[0;31m# print(all_faces)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0melapsed_detection_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/retinaface/predict_single.py\u001b[0m in \u001b[0;36mpredict_jsons\u001b[0;34m(self, image, confidence_threshold, nms_threshold)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mtorched_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_from_rgb_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mland\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorched_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/retinaface/network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# FPN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mout_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 440\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH5jW0j1ZJIU",
        "outputId": "4c9cc353-f067-4093-c48e-8fb803d79b2e"
      },
      "source": [
        "    print(f'Decode Time:\\n Mean: {np.mean(elapsed_decode_time)} seconds,\\n All: {np.sum(elapsed_decode_time)/60.0} mins')\n",
        "    print(f'Detection Time:\\n Mean: {np.mean(elapsed_detection_time)} seconds,\\n All: {np.sum(elapsed_detection_time)/60.0} mins')\n",
        "    print(f'Time For Checking Quality Of Trackers:\\n Mean: {np.mean(elapsed_checkquality_time)} seconds,\\n All: {np.sum(elapsed_checkquality_time)/60.0} mins')\n",
        "    print(f'Time For Checking For New Trackers:\\n Mean: {np.mean(elapsed_checkForNewTracker_time)} seconds,\\n All: {np.sum(elapsed_checkForNewTracker_time)/60.0} mins')\n",
        "    print(f'Time For Labelling And Saving Faces:\\n Mean: {np.mean(elapsed_faceExtraction_time)} seconds,\\n All: {np.sum(elapsed_faceExtraction_time)/60.0} mins')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decode Time:\n",
            " Mean: 0.002061899503072103 seconds,\n",
            " All: 0.05979508558909098 mins\n",
            "Detection Time:\n",
            " Mean: 24.527051681695983 seconds,\n",
            " All: 17.57772037188212 mins\n",
            "Time For Checking Quality Of Trackers:\n",
            " Mean: 0.029441905432733995 seconds,\n",
            " All: 0.8538152575492859 mins\n",
            "Time For Checking For New Trackers:\n",
            " Mean: 0.007171736207119254 seconds,\n",
            " All: 0.005139744281768799 mins\n",
            "Time For Labelling And Saving Faces:\n",
            " Mean: 0.014532128969828287 seconds,\n",
            " All: 0.4214317401250203 mins\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31Ge4bd4rCE5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}